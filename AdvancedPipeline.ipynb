{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM GPU Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r /opt/conda/lib/python3.6/site-packages/lightgbm\n",
    "!git clone --recursive https://github.com/Microsoft/LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt-get install -y -qq libboost-all-dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and re-install LightGBM with GPU support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd LightGBM\n",
    "rm -r build\n",
    "mkdir build\n",
    "cd build\n",
    "cmake -DUSE_GPU=1 -DOpenCL_LIBRARY=/usr/local/cuda/lib64/libOpenCL.so -DOpenCL_INCLUDE_DIR=/usr/local/cuda/include/ ..\n",
    "make -j$(nproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd LightGBM/python-package/;python3 setup.py install --precompile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p /etc/OpenCL/vendors && echo \"libnvidia-opencl.so.1\" > /etc/OpenCL/vendors/nvidia.icd\n",
    "!rm -r LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE, RFECV\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn.pipeline import make_pipeline, FeatureUnion, Pipeline\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, cross_validate\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score \n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_curve, roc_auc_score, auc, log_loss\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the patch prior to the code patch and access the \"data\" folder\n",
    "PATH = os.path.join(os.path.dirname(os.getcwd()), \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_test_data(path=PATH):\n",
    "    train_path = os.path.join(path, \"train.csv\")\n",
    "    test_path = os.path.join(path, \"test.csv\")\n",
    "    return pd.read_csv(train_path), pd.read_csv(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = load_train_test_data(PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"Train shape\", train.shape\n",
    "print \"Test shape\", test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = train.drop(\"Cover_Type\", axis=1)\n",
    "var_resp = train[\"Cover_Type\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View % of each class of var response\n",
    "(var_resp.value_counts()/var_resp.count())*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the break between training and testing before any treatment at the base to avoid missings biases and other particularities\n",
    "# Stratify is useful for small datasets, unbalanced datasets or multiclass classification\n",
    "# For small datasets, k-fold or leave-one-out is better than holdout\n",
    "x_train, x_test, y_train, y_test = train_test_split(variables, var_resp, test_size=0.2, random_state=2, stratify=var_resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count null for each column\n",
    "x_train.isnull().sum()[x_train.isnull().sum() > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check constant features to delete them\n",
    "feats_counts = x_train.nunique(dropna = False, axis=1) == 1\n",
    "\n",
    "constant_features = feats_counts.loc[feats_counts==1].index.tolist()\n",
    "print (constant_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check duplicated features to delete them\n",
    "x_train.T.duplicated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.corr()\n",
    "plt.matshow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.mean().sort_values().plot(style='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See correlation between base variables\n",
    "corr = x_train.loc[:, x_train.columns != 'Id'].corr()\n",
    "corr.style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See correlation of variables with the response variable\n",
    "corr_with_y = pd.DataFrame(x_train.corrwith(y_train).abs()).reset_index()\n",
    "corr_with_y.columns = [\"Feature\", \"Correlation with Target\"]\n",
    "corr_with_y = corr_with_y.sort_values(by=\"Correlation with Target\", ascending=False)\n",
    "corr_with_y.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering:\n",
    "# \n",
    "def add_features(data):\n",
    "    data[\"Teste\"] = data[\"Teste_1\"]\n",
    "return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = add_features(x_train)\n",
    "x_test = add_features(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop identity and other columns\n",
    "columns = [\"Id\", constant_features]\n",
    "\n",
    "x_train.drop(columns, axis = 1, inplace = True)\n",
    "x_test.drop(columns, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing for numeric and categoric variables\n",
    "# Tree-based models doesn't depend on scaling\n",
    "# Non Tree-based models hugely depend on scaling\n",
    "# We use preprocessing (StardardScaler or MinMaxScaler) to scale all features to one scale, so that their initial impact on the model will be roughly similar.\n",
    "# Log or SQRT functions help linear models and neural networks by making large values approach the mean and small values more distinguishable\n",
    "num_pipeline = Pipeline([\n",
    "        ('selector', VarianceThreshold()),\n",
    "        ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "        ('std_scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "# One-Hot can be useful in linear methods, Knn and neural networks.\n",
    "# But for tree methods, this can increase the complexity of the model.\n",
    "# If the number of classes in each 'One-Hot' column is large, we can store the final base in a sparse array, so we don't 'keep' the zeros in memory\n",
    "cat_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy=\"most_frequent\")),\n",
    "        ('oneHot', OneHotEncoder())\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_attribs = variables.select_dtypes(include=np.number).columns.tolist()\n",
    "cat_attribs = variables.select_dtypes(include='object').columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer([\n",
    "        (\"num\", num_pipeline, num_attribs),\n",
    "        (\"cat\", cat_pipeline, cat_attribs),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling with hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum number of levels in tree\n",
    "# Decrease to previne overfit\n",
    "max_depth = [int(x) for x in np.linspace(2, 50, num = 4)]\n",
    "max_depth.append(None, -1)\n",
    "\n",
    "param_grid_extratrees = {\n",
    "    'reduce_dim__n_components': [0.8, 0.9],\n",
    "    'classify__learning_rate': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1],\n",
    "    # Number of trees in estimator. Increase to previne overfit\n",
    "    'classify__n_estimators': [int(x) for x in np.linspace(start = 100, stop = 2000, num = 8)],\n",
    "    'classify__max_depth': max_depth,\n",
    "    'classify__min_samples_split': [2, 3, 5, 7, 9],\n",
    "    # Never be equal 1 why this means the tree in the end could potentially have one leaf for each sample. This 100% will overfit.    \n",
    "    'classify__min_samples_leaf': [2, 4, 6, 8]\n",
    "    # The number of features to consider when looking for the best split, default value is auto.\n",
    "    'classify__max_features': ['sqrt', 'log2', None],\n",
    "    'classify__class_weight': ['balanced', 'balanced_subsample'],\n",
    "    'classify__gamma': [i/10.0 for i in range(3)],\n",
    "    'classify__colsample_bytree': [i/10.0 for i in range(1, 3)]\n",
    "}\n",
    "\n",
    "param_grid_logreg = [\n",
    "    {\n",
    "        'reduce_dim__n_components': [0.8, 0.9],\n",
    "        'classify__class_weight': [None, 'balanced'],\n",
    "        'classify__C': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1],\n",
    "        'classify__max_iter': [int(x) for x in np.linspace(start = 100, stop = 2000, num = 8)],\n",
    "        'classify__penalty': ['l1', 'l2']\n",
    "    }\n",
    "]\n",
    "\n",
    "# https://github.com/Microsoft/LightGBM/issues/695#issuecomment-315591634\n",
    "param_grid_lgbm = [\n",
    "    {\n",
    "        'reduce_dim__n_components': [0.8, 0.9],\n",
    "        'classify__extra_trees': [False, True],\n",
    "        'classify__learning_rate': [0.0001, 0.001, 0.01, 0.1],\n",
    "        'classify__n_estimators': [int(x) for x in np.linspace(start = 100, stop = 2000, num = 8)],\n",
    "        'max_depth': max_depth\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('reduce_dim', PCA(svd_solver='full')),\n",
    "        ('classify', RandomForestClassifier(n_jobs=-1))\n",
    "])\n",
    "\n",
    "# GridSearchCV with F1 that is robust against unbalanced datasets\n",
    "grid_search = GridSearchCV(\n",
    "    pipe, param_grid, cv=5, scoring='accuracy', verbose=1, return_train_score=True, n_jobs=-1)\n",
    "\n",
    "grid_search = grid_search.fit(variables, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/a/33504368\n",
    "test_prepared = grid_search.best_estimator_.named_steps['preprocessor'].transform(x_test)\n",
    "test_prepared = grid_search.best_estimator_.named_steps['reduce_dim'].transform(test_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_estimator_.named_steps['classify'].score(test_prepared, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_imp = pd.DataFrame(sorted(zip(model._final_estimator.feature_importances_,x_train.columns)), columns=['Value','Feature'])\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "sns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.sort_values(by=\"Value\", ascending=False)[:20])\n",
    "plt.title('RandomForest Feature Importance - Top 20')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.savefig('RandomForest_importances.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_estimation = model.named_steps['classify'].predict(test_prepared)\n",
    "y_test_score = model.named_steps['classify'].predict_proba(test_prepared)[:,1]\n",
    "print(\"Test score: \",y_test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_report = classification_report(y_test, y_test_estimation, digits=4)\n",
    "print(\"Test:\\n\",test_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If number of classes if greater than 2, then is multiclass and make a adaptive roc curve. \n",
    "# Else if binary class and make normal roc curve\n",
    "if(len(y_test.unique()) == 2):\n",
    "    y_pred_proba = model.named_steps['classify'].predict_proba(test_prepared)\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "else:\n",
    "    y_pred_proba = model.named_steps['classify'].predict_proba(test_prepared)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ROC curve and ROC area for binary class\n",
    "def plot_roc_curve_binary(fpr, tpr):\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, linewidth=2, label='ROC curve (area = %0.3f)' % auc(fpr, tpr))\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.axis([0, 1, 0, 1])\n",
    "    plt.xlabel('False Positive Rate', fontsize=16)\n",
    "    plt.ylabel('True Positive Rate', fontsize=16)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "plot_roc_curve_binary(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ROC curve and ROC area for each class\n",
    "def plot_roc_curve_multiclass(y_test, y_pred_proba):\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    y_test_dummies = pd.get_dummies(y_test, drop_first=False).values\n",
    "    for i in range(len(y_test.unique())):\n",
    "        fpr[i], tpr[i], thresholds = roc_curve(y_test_dummies[:, i], y_predicted[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    # Plot of a ROC curve for a specific class\n",
    "    for i in range(len(y_test.unique())):\n",
    "        plt.figure()\n",
    "        plt.plot(fpr[i], tpr[i], label='ROC curve (area = %0.2f)' % roc_auc[i])\n",
    "        plt.plot([0, 1], [0, 1], 'k--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('Receiver operating characteristic example')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We apply the same changes we made in training to the official test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = add_features(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ID = test['Id'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop identity and other columns\n",
    "columns = [\"Id\"]\n",
    "\n",
    "test.drop(columns, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test = grid_search.best_estimator_.named_steps['preprocessor'].transform(test)\n",
    "final_test = grid_search.best_estimator_.named_steps['reduce_dim'].transform(final_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted_test = grid_search.best_estimator_.named_steps['classify'].predict(final_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.DataFrame({'Id': test_ID, 'Cover_Type': y_predicted_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv('RandomForest_output.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
