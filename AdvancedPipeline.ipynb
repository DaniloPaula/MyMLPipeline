{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFE, RFECV\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn.pipeline import make_pipeline, FeatureUnion, Pipeline\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, cross_validate\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score \n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_curve, roc_auc_score, auc, log_loss\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acessar o patch anterior ao patch do código e acessar a pasta \"data\"\n",
    "PATH = os.path.join(os.path.dirname(os.getcwd()), \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_test_data(path=PATH):\n",
    "    train_path = os.path.join(path, \"train.csv\")\n",
    "    test_path = os.path.join(path, \"test.csv\")\n",
    "    return pd.read_csv(train_path), pd.read_csv(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = load_train_test_data(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = train.drop(\"Cover_Type\", axis=1)\n",
    "var_resp = train[\"Cover_Type\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ver % de cada classe da var resposta\n",
    "(var_resp.value_counts()/var_resp.count())*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fazer a quebra entre treino e teste antes de qualquer tratamento na base\n",
    "x_train, x_test, y_train, y_test = train_test_split(variables, var_resp, test_size=0.2, random_state=2, stratify=var_resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering:\n",
    "# \n",
    "def add_features(data):\n",
    "    data[\"Teste\"] = data[\"Teste_1\"]\n",
    "return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = add_features(x_train)\n",
    "x_test = add_features(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ver correlação entre variáveis da base\n",
    "corr = x_train.loc[:, x_train.columns != 'Id'].corr()\n",
    "corr.style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ver correlação das variáveis com a variável resposta\n",
    "corr_with_y = pd.DataFrame(x_train.corrwith(y_train).abs()).reset_index()\n",
    "corr_with_y.columns = [\"Feature\", \"Correlation with Cover_Type\"]\n",
    "corr_with_y = corr_with_y.sort_values(by=\"Correlation with Cover_Type\", ascending=True)\n",
    "corr_with_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropar colunas identidade e outras\n",
    "columns = [\"Id\"]\n",
    "\n",
    "x_train.drop(columns, axis = 1, inplace = True)\n",
    "x_test.drop(columns, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing for numeric and cat variables\n",
    "num_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "        ('std_scaler', StandardScaler()),\n",
    "    ])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy=\"most_frequent\")),\n",
    "        ('oneHot', OneHotEncoder()),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_attribs = variables.select_dtypes(include=np.number).columns.tolist()\n",
    "cat_attribs = variables.select_dtypes(include='object').columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pipeline = ColumnTransformer([\n",
    "        (\"num\", num_pipeline, num_attribs),\n",
    "        (\"cat\", cat_pipeline, cat_attribs),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prepared = full_pipeline.fit_transform(variables)\n",
    "test_prepared = full_pipeline.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling with hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 200, num = 4)]\n",
    "max_depth.append(None)\n",
    "\n",
    "param_grid = {\n",
    "    'learning_rate': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1],\n",
    "    'n_estimators': [int(x) for x in np.linspace(start = 100, stop = 2000, num = 8)],\n",
    "    'max_depth': max_depth,\n",
    "    'min_samples_split': [2, 3, 5, 7, 9],\n",
    "    'min_samples_leaf': [1, 2, 4, 6, 8],\n",
    "    # The number of features to consider when looking for the best split, default value is auto.\n",
    "    'max_features' = ['sqrt', 'log2', None],\n",
    "    \n",
    "    'gamma': [i/10.0 for i in range(3)],\n",
    "    'colsample_bytree': [i/10.0 for i in range(1, 3)],\n",
    "#     Only for logistic regression\n",
    "    'class_weight' = [None, 'balanced'],\n",
    "    'C' = [0.001, 0.009, 0.01, 0.09, 0.1, 0.5, 1, 3, 5, 10, 50],\n",
    "    'max_iter' = [500, 700, 1000]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {\n",
    "        'reduce_dim__n_components': [0.5, 0.7, 0.9],\n",
    "        'classify__max_depth': max_depth,\n",
    "        'classify__n_estimators': n_estimators,\n",
    "        'classify__max_features': max_features\n",
    "    }\n",
    "]\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    Pipeline([\n",
    "        ('reduce_dim', PCA(svd_solver='full')),\n",
    "        ('classify', RandomForestClassifier(n_jobs=-1))\n",
    "    ]), param_grid, cv=5, scoring='accuracy', verbose=1, return_train_score=True, n_jobs=-1)\n",
    "\n",
    "grid_search = grid_search.fit(train_prepared, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_estimator_.score(test_prepared, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_imp = pd.DataFrame(sorted(zip(model._final_estimator.feature_importances_,x_train.columns)), columns=['Value','Feature'])\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "sns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.sort_values(by=\"Value\", ascending=False)[:20])\n",
    "plt.title('LightGBM Feature Importance - Top 20')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.savefig('lgbm_importances.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_estimation = model.predict(train_prepared)\n",
    "y_test_estimation = model.predict(test_prepared)\n",
    "\n",
    "y_train_score = model.predict_proba(train_prepared)[:,1]\n",
    "y_test_score = model.predict_proba(test_prepared)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_report = classification_report(y_train, y_train_estimation, digits=4)\n",
    "print(\"Train:\\n\",train_report)\n",
    "\n",
    "test_report = classification_report(y_test, y_test_estimation, digits=4)\n",
    "print(\"Test:\\n\",test_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = grid_search.predict_proba(test_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = model.predict_proba(x_test)[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(fpr, tpr):\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, linewidth=2, label='ROC curve (area = %0.3f)' % auc(fpr, tpr))\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.axis([0, 1, 0, 1])\n",
    "    plt.xlabel('Taxa de falsos positivos', fontsize=16)\n",
    "    plt.ylabel('True Positive Rate', fontsize=16)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "plot_roc_curve(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "y_test_dummies = pd.get_dummies(y_test, drop_first=False).values\n",
    "for i in range(len(y_test.unique())):\n",
    "    fpr[i], tpr[i], thresholds = roc_curve(y_test_dummies[:, i], y_predicted[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plot of a ROC curve for a specific class\n",
    "for i in range(len(y_test.unique())):\n",
    "    plt.figure()\n",
    "    plt.plot(fpr[i], tpr[i], label='ROC curve (area = %0.2f)' % roc_auc[i])\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicamos as mesmas mudanças que fizemos no treino, para o teste oficial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = add_features(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ID = test['Id'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropar colunas identidade e outras\n",
    "columns = [\"Id\"]\n",
    "\n",
    "test.drop(columns, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test = full_pipeline.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted_test = grid_search.predict(final_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.DataFrame({'Id': test_ID, 'Cover_Type': y_predicted_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv('RandomForest_output.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
